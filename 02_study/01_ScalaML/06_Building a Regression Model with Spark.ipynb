{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 5장에서는 결과가 이산형 분류로 표현되는 분류모델을 다루었지만, 이번장에서는 목표변수( 종속 )변수가 실수값을 갖는 회귀모형( regression )모델을 다룸.\n",
    "- 회귀모형도 분류모델과 같이 지도학습( supervised learning )에 속함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression models의 사용예\n",
    "- 주식가격 및 경제지표 예측\n",
    "- 부도에 의한 손실에 예측(  분류모델을 부도확률을 예측 )\n",
    "- 추천( 사용자의 특성치를 고려함 )\n",
    "- 행위와 소비패턴을 고려한 고객 생애 가치( Customer Lifetime Value, CLTV )를 예측\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이번장의 내용\n",
    "- MLlib에 있는 회귀모형에서 사용가능한 자료형태\n",
    "- 특성 추출과 회귀모형을 위한 목표변수 변환\n",
    "- MLlib을 사용해서 회귀모형을 훈련\n",
    "- 훈련된 회귀모형을 이용해서 예측방법\n",
    "- 교차 유효성 검사(cross-validation)를 이용해서 회귀모형의 여러가지 파라메타가 성능에 미치는 영향을 조사"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Types of regression models "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Least squares regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L1 regularization은 오차의 절대값을 합\n",
    "- L2 regularization은 오차의 제곱합을 ROOT 처리한 방식\n",
    "\n",
    "- L1 regularization을 적용한 방식을  lasso regression\n",
    "- L2 regularization을 적용한 방식을  ridge regression( 일반적인 방식 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![행렬을 이용한 중회귀모형](regress_01.jpg \"행렬을 이용한 중회귀모형\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![행렬을 이용한 중회귀모형](regress_02.jpg \"행렬을 이용한 중회귀모형\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![행렬을 이용한 중회귀모형](regress_03.jpg \"행렬을 이용한 중회귀모형\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![행렬을 이용한 중회귀모형](regress_04.jpg \"행렬을 이용한 중회귀모형\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Decision trees for regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- x 축이 input 변수,  y축이 목표변수\n",
    "- 빨간색 선은 선형모델의 예측함수를 보여주고,  녹색선은 decision tree의 예측함수를 보여줌"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Linear model and decision tree prediction functions for regression](regress_05.jpg \"Linear model and decision tree prediction functions for regression\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Extracting the right features from your data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 분류모델과 같이 input features( 독립변수 )을 만들고, 실질적인 차이는 목표변수( 종속변수 )가 실수값임.\n",
    "- MLlib에서는 LabeledPoint 클래스가 Double type으로 label 필드가 제공하고, 목표변수로 지정함."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Extracting features from the bike sharing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 도시 자전거 공유 시스템에서 발생한 자전거의 일별, 시간별 렌탈정보 \n",
    "- 날짜와 시간, 날씨, 계절, 휴일정보가 포함\n",
    "- http://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset 에서 제공\n",
    "-  wget http://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip \n",
    "- 파일 구성 : readme.txt, hour.csv, day.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### readme.txt의 내용\n",
    "- 1) instant: This is the record ID\n",
    "- 2) dteday: This is the raw date\n",
    "- 3)  season: This is different seasons such as spring, summer, winter, and fall\n",
    "- 4)  yr: This is the year (2011 or 2012)\n",
    "- 5)  mnth: This is the month of the year\n",
    "- 6)  hr: This is the hour of the day\n",
    "- 7)  holiday: This is whether the day was a holiday or not\n",
    "- 8)  weekday: This is the day of the week\n",
    "- 9)  workingday: This is whether the day was a working day or not\n",
    "- 10)  weathersit: This is a categorical variable that describes the weather at a particular time\n",
    "- 11)  temp: This is the normalized temperature\n",
    "- 12)  atemp: This is the normalized apparent temperature\n",
    "- 13)  hum: This is the normalized humidity( 습도 ) \n",
    "- 14)  windspeed: This is the normalized wind speed( 바람세기 )\n",
    "- 15)  cnt: This is the target variable, that is, the count of bike rentals for that hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hour.csv은 헤더에 컬럼명을 포함하고 있어서 헤더를 제거가 필요\n",
    "- sed 1d hour.csv > hour_noheader.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PySpark shell 시작하고 데이터 로딩과 보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "$ MASTER=local[4]  bin/pyspark\n",
    "path = \"data/hour_noheader.csv\"\n",
    "raw_data = sc.textFile(path)\n",
    "num_data = raw_data.count()\n",
    "records = raw_data.map(lambda x: x.split(\",\"))\n",
    "first = records.first()\n",
    "print first\n",
    "print num_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- record ID, raw date 컬럼은 무시\n",
    "- 목표변수 cnt는 casual와 registered의 값의 합이기 때문에, casual와 registered 컬럼들도 무시\n",
    "- 독립변수는 12개이고, 1 ~ 8 변수까지는 범주형( categorical)이고, 나머지 4개는 표준화된 실수값( 0.0 ~ 1.0 )\n",
    "- records 에 저장된 데이터를 여러번 사용하기 위해서 캐싱 처리함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "records.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 범주형 변수 8개는 binary encoding 처리 필요\n",
    "- get_mapping()함수는  범주형 변수를 Python의 dictionary변수로 추출하는 함수\n",
    "- 2번째 범수를 추출해봄."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mapping(rdd, idx):\n",
    "    return rdd.map(lambda fields: fields[idx]).distinct().zipWithIndex().collectAsMap()\n",
    "\n",
    "\n",
    "print \"Mapping of first categorical feasture column: %s\" % get_mapping(records, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 각각의 모든 범주형 변수에 대해서 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mappings = [get_mapping(records, i) for i in range(2,10)]\n",
    "cat_len = sum(map(len, mappings))\n",
    "num_len = len(records.first()[11:15])\n",
    "total_len = num_len + cat_len\n",
    "\n",
    "\n",
    "print \"Feature vector length for categorical features: %d\" % cat_len\n",
    "print \"Feature vector length for numerical features: %d\" % num_len\n",
    "print \"Total feature vector length: %d\" % total_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Creating feature vectors for the linear model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 범주형 값들을 모두 각각 지시변수로 만드는 과정과 연속형변수와 합쳐주는 함수 작성\n",
    "- 선형대수(linear algebra) util LIB인 numpy를 사용함\n",
    "- LabeledPoint 클래스에 목표변수와 독립변수들을 맵핑함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np\n",
    "\n",
    "def extract_features(record):\n",
    "    cat_vec = np.zeros(cat_len)\n",
    "    i = 0\n",
    "    step = 0\n",
    "    for field in record[2:9]:\n",
    "        m = mappings[i]\n",
    "        idx = m[field]\n",
    "        cat_vec[idx + step] = 1\n",
    "        i = i + 1\n",
    "        step = step + len(m)\n",
    "    num_vec = np.array([float(field) for field in record[10:14]])\n",
    "    return np.concatenate((cat_vec, num_vec))\n",
    "\n",
    "\n",
    "def extract_label(record):\n",
    "    return float(record[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- extract_features()와 extract_label()을 이용해서 독립변수(특성치)을 뽑아내고 각각의 레코드에 대해서 lable을 생성\n",
    "- 그리고, 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = records.map(lambda r: LabeledPoint(extract_label(r), extract_features(r)))\n",
    "\n",
    "first_point = data.first()\n",
    "print \"Raw data: \" + str(first[2:])\n",
    "print \"Label: \" + str(first_point.label)\n",
    "print \"Linear Model feature vector:\\n\" + str(first_point.features)\n",
    "print \"Linear Model feature vector length: \" + str(len(first_point.features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Creating feature vectors for the decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features_dt(record):\n",
    "    return np.array(map(float, record[2:14]))\n",
    "\n",
    "data_dt = records.map(lambda r: LabeledPoint(extract_label(r),\n",
    "extract_features_dt(r)))\n",
    "first_point_dt = data_dt.first()\n",
    "print \"Decision Tree feature vector: \" + str(first_point_dt.features)\n",
    "print \"Decision Tree feature vector length: \" +\n",
    "str(len(first_point_dt.features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Training and using regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 이전에 만든 훈련데이터( [LabeledPoint] RDD )을 train()함수에 넣어주면 훈련이 가능함.\n",
    "- SGD( Stochastic gradient descent , 확률적 기울기 하강 )은 함수의 극대값 또는 극소값을 구하기 위해 현재 위치에서 함수값의 변화가 가장 큰 방향으로 이동한다는 것\n",
    "![확률적 기울기 하강](regress_06.jpg \"확률적 기울기 하강\")\n",
    "![확률적 기울기 하강](regress_07.jpg \"확률적 기울기 하강\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LinearRegressionWithSGD\n",
    "from pyspark.mllib.tree import DecisionTree\n",
    "\n",
    "help(LinearRegressionWithSGD.train)\n",
    "\n",
    "help(DecisionTree.trainRegressor)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Training a regression model on the bike sharing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_model = LinearRegressionWithSGD.train(data, iterations=10, step=0.1, intercept=False) \n",
    "\n",
    "true_vs_predicted = data.map( lambda p: (p.label, linear_model.predict(p.features)) )\n",
    "print \"Linear Model predictions: \" + str(true_vs_predicted.take(5) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dt_model = DecisionTree.trainRegressor(data_dt,{})\n",
    "preds = dt_model.predict(data_dt.map(lambda p: p.features))\n",
    "actual = data.map(lambda p: p.label)\n",
    "true_vs_predicted_dt = actual.zip(preds)\n",
    "\n",
    "print \"Decision Tree predictions: \" + str(true_vs_predicted_dt.take(5))\n",
    "print \"Decision Tree depth: \" + str(dt_model.depth())\n",
    "print \"Decision Tree number of nodes: \" + str(dt_model.numNodes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluating the performance of regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Mean Squared Error and Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MSE](regress_08.jpg \"MSE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squared_error(actual, pred):\n",
    "    return (pred - actual)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Mean Absolute Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MAE](regress_09.jpg \"MAE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def abs_error(actual, pred):\n",
    "    return np.abs(pred - actual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Root Mean Squared Log Error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 목표변수의 범위가 넓을때 유용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. The R-squared coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 결정 계수( coefficient of determination )라고 잘 알려짐.\n",
    "- (전체변동 - 에러변동 ) / 전체변동  ==  모델에 의한 변동 / 전체변동\n",
    "- 0 ~ 1 사이값을 갖으며, 1에 가까울수록 모델의 설명력이 높음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def squared_log_error(pred, actual):\n",
    "    return (np.log(pred + 1) - np.log(actual + 1))**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. Computing performance metrics on the bike sharing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1. Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse = true_vs_predicted.map(lambda (t, p): squared_error(t, p)).mean()\n",
    "mae = true_vs_predicted.map(lambda (t, p): abs_error(t, p)).mean()\n",
    "rmsle = np.sqrt(true_vs_predicted.map(lambda (t, p): squared_log_error(t, p)).mean())\n",
    "print \"Linear Model - Mean Squared Error: %2.4f\" % mse\n",
    "print \"Linear Model - Mean Absolute Error: %2.4f\" % mae\n",
    "print \"Linear Model - Root Mean Squared Log Error: %2.4f\" % rmsle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2. Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mse_dt = true_vs_predicted_dt.map(lambda (t, p): squared_error(t, p)).mean()\n",
    "mae_dt = true_vs_predicted_dt.map(lambda (t, p): abs_error(t, p)).mean()\n",
    "rmsle_dt = np.sqrt(true_vs_predicted_dt.map(lambda (t, p): squared_log_error(t, p)).mean())\n",
    "print \"Decision Tree - Mean Squared Error: %2.4f\" % mse_dt\n",
    "print \"Decision Tree - Mean Absolute Error: %2.4f\" % mae_dt\n",
    "print \"Decision Tree - Root Mean Squared Log Error: %2.4f\" %rmsle_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Improving model performance and tuning parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Transforming the target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala 2.11",
   "language": "scala211",
   "name": "scala211"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": "scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "pygments_lexer": "scala",
   "version": "2.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
